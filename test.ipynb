{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b14918",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLINER_TO_CANON = {\n",
    "    # ---- People & Orgs ----\n",
    "    \"person\": \"PERSON\",\n",
    "    \"name\": \"PERSON\",\n",
    "    \"first_name\": \"PERSON\",\n",
    "    \"last_name\": \"PERSON\",\n",
    "    \"organization\": \"ORG\",\n",
    "    \"organisation\": \"ORG\",\n",
    "    \"company\": \"ORG\",\n",
    "    \"org\": \"ORG\",\n",
    "\n",
    "    # ---- Contact ----\n",
    "    \"email\": \"EMAIL_ADDRESS\",\n",
    "    \"email_address\": \"EMAIL_ADDRESS\",\n",
    "    \"phone\": \"UK_PHONE_NUMBER\",\n",
    "    \"phone_number\": \"UK_PHONE_NUMBER\",\n",
    "    \"mobile\": \"UK_PHONE_NUMBER\",\n",
    "\n",
    "    # ---- Network ----\n",
    "    \"ip\": \"IP_ADDRESS\",\n",
    "    \"ip_address\": \"IP_ADDRESS\",\n",
    "\n",
    "    # ---- Dates ----\n",
    "    \"date\": \"DATE\",\n",
    "    \"date_time\": \"DATE\",\n",
    "    \"datetime\": \"DATE\",\n",
    "\n",
    "    # ---- Geography (privacy-safe) ----\n",
    "    # Treat full address as its own PII type when available, otherwise fall back to\n",
    "    # postcode/street/city/etc as LOCATION/UK_POSTCODE.\n",
    "    \"address\": \"UK_ADDRESS\",\n",
    "    \"street_address\": \"UK_ADDRESS\",\n",
    "    \"full_address\": \"UK_ADDRESS\",\n",
    "\n",
    "    \"location\": \"LOCATION\",\n",
    "    \"city\": \"LOCATION\",\n",
    "    \"town\": \"LOCATION\",\n",
    "    \"state\": \"LOCATION\",\n",
    "    \"province\": \"LOCATION\",\n",
    "    \"region\": \"LOCATION\",\n",
    "    \"country\": \"LOCATION\",\n",
    "    \"place\": \"LOCATION\",\n",
    "\n",
    "    # ---- UK specific ----\n",
    "    \"postcode\": \"UK_POSTCODE\",\n",
    "    \"uk_postcode\": \"UK_POSTCODE\",\n",
    "\n",
    "    # ---- Banking ----\n",
    "    \"uk_iban\": \"UK_IBAN\",\n",
    "    \"iban\": \"UK_IBAN\",\n",
    "    \"sort_code\": \"UK_SORT_CODE\",\n",
    "    \"uk_sort_code\": \"UK_SORT_CODE\",\n",
    "    \"account_number\": \"UK_ACCOUNT_NUMBER\",\n",
    "    \"uk_account_number\": \"UK_ACCOUNT_NUMBER\",\n",
    "\n",
    "    # ---- Cards ----\n",
    "    \"credit_card_number\": \"CREDIT_CARD_NUMBER\",\n",
    "    \"card_number\": \"CREDIT_CARD_NUMBER\",\n",
    "    \"card_expiry\": \"CARD_EXPIRY\",\n",
    "    \"expiry\": \"CARD_EXPIRY\",\n",
    "    \"expiration_date\": \"CARD_EXPIRY\",\n",
    "\n",
    "    # ---- IDs ----\n",
    "    \"transaction_id\": \"TRANSACTION_ID\",\n",
    "    \"support_ticket_number\": \"SUPPORT_TICKET_NUMBER\",\n",
    "    \"session_id\": \"SESSION_ID\",\n",
    "    \"customer_reference\": \"CUSTOMER_REFERENCE\",\n",
    "    \"account_id\": \"ACCOUNT_ID\",\n",
    "    \"internal_id\": \"INTERNAL_ID\",\n",
    "}\n",
    "CANON_LABELS = {\n",
    "    # Identity\n",
    "    \"PERSON\",\n",
    "    \"ORG\",\n",
    "\n",
    "    # Contact\n",
    "    \"EMAIL_ADDRESS\",\n",
    "    \"UK_PHONE_NUMBER\",\n",
    "    \"IP_ADDRESS\",\n",
    "\n",
    "    # Time\n",
    "    \"DATE\",\n",
    "    \"DATE_OF_BIRTH\",\n",
    "\n",
    "    # Geography (privacy-safe)\n",
    "    \"LOCATION\",   \n",
    "    \"UK_POSTCODE\", \n",
    "    \"UK_ADDRESS\", \n",
    "\n",
    "    # Banking\n",
    "    \"UK_SORT_CODE\",\n",
    "    \"UK_ACCOUNT_NUMBER\",\n",
    "    \"UK_IBAN\",\n",
    "\n",
    "    # Cards\n",
    "    \"CREDIT_CARD_NUMBER\",\n",
    "    \"CARD_EXPIRY\",\n",
    "\n",
    "    # IDs\n",
    "    \"TRANSACTION_ID\",\n",
    "    \"CUSTOMER_REFERENCE\",\n",
    "    \"SESSION_ID\",\n",
    "    \"SUPPORT_TICKET_NUMBER\",\n",
    "    \"ACCOUNT_ID\",\n",
    "    \"INTERNAL_ID\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db96d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "PRIORITY = {\n",
    "    \"UK_IBAN\": 120,\n",
    "    \"CREDIT_CARD_NUMBER\": 115,\n",
    "    \"UK_SORT_CODE\": 110,\n",
    "    \"UK_ACCOUNT_NUMBER\": 108,\n",
    "    \"CARD_EXPIRY\": 105,\n",
    "\n",
    "    \"EMAIL_ADDRESS\": 95,\n",
    "    \"IP_ADDRESS\": 95,\n",
    "    \"UK_PHONE_NUMBER\": 92,\n",
    "\n",
    "    \"UK_ADDRESS\": 88,\n",
    "    \"UK_POSTCODE\": 85,\n",
    "\n",
    "    \"TRANSACTION_ID\": 75,\n",
    "    \"SUPPORT_TICKET_NUMBER\": 74,\n",
    "    \"SESSION_ID\": 73,\n",
    "    \"CUSTOMER_REFERENCE\": 72,\n",
    "    \"ACCOUNT_ID\": 71,\n",
    "    \"INTERNAL_ID\": 70,\n",
    "\n",
    "    \"DATE_OF_BIRTH\": 55,\n",
    "    \"DATE\": 50,\n",
    "    \"PERSON\": 40,\n",
    "    \"ORG\": 35,\n",
    "}\n",
    "ALLOWED_CANON = set(CANON_LABELS)\n",
    "\n",
    "# --- Regex backstops for common misses (landlines, IPv4, postcodes, address lines) ---\n",
    "_IPV4_RE = re.compile(r\"\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b\")\n",
    "_UK_POSTCODE_RE = re.compile(r\"\\b([A-Z]{1,2}\\d[A-Z\\d]?\\s*\\d[A-Z]{2})\\b\", re.IGNORECASE)\n",
    "_UK_LANDLINE_RE = re.compile(r\"(?<!\\w)0\\d{2,4}\\s?\\d{3,4}\\s?\\d{3,4}(?!\\w)\")\n",
    "_UK_MOBILE_INTL_RE = re.compile(r\"(?<!\\w)\\+44\\s?7\\d{3}\\s?\\d{6}(?!\\w)\")\n",
    "\n",
    "def _is_valid_ipv4(s: str) -> bool:\n",
    "    parts = s.split(\".\")\n",
    "    if len(parts) != 4:\n",
    "        return False\n",
    "    try:\n",
    "        nums = [int(p) for p in parts]\n",
    "    except Exception:\n",
    "        return False\n",
    "    return all(0 <= n <= 255 for n in nums)\n",
    "\n",
    "def _expand_to_address_line(text: str, start: int, end: int) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    If the span (usually a postcode) sits inside a line that looks like a full address,\n",
    "    expand to the full line boundaries.\n",
    "    \"\"\"\n",
    "    line_start = text.rfind(\"\\n\", 0, start)\n",
    "    line_start = 0 if line_start == -1 else line_start + 1\n",
    "    line_end = text.find(\"\\n\", end)\n",
    "    line_end = len(text) if line_end == -1 else line_end\n",
    "\n",
    "    raw_line = text[line_start:line_end]\n",
    "    line = raw_line.strip()\n",
    "    if not line:\n",
    "        return None\n",
    "\n",
    "    # Heuristics: commas + digits + some street/country-ish token => likely address line\n",
    "    lc = line.lower()\n",
    "    if line.count(\",\") < 2:\n",
    "        return None\n",
    "    if not re.search(r\"\\d\", line):\n",
    "        return None\n",
    "    if not any(tok in lc for tok in [\"street\", \"st\", \"road\", \"rd\", \"avenue\", \"ave\", \"lane\", \"ln\", \"drive\", \"dr\", \"flat\", \"apt\", \"apartment\", \"unit\", \"uk\", \"united kingdom\", \"london\"]):\n",
    "        return None\n",
    "\n",
    "    # Map back to exact offsets excluding surrounding whitespace\n",
    "    left_ws = len(raw_line) - len(raw_line.lstrip())\n",
    "    right_ws = len(raw_line) - len(raw_line.rstrip())\n",
    "    return line_start + left_ws, line_end - right_ws\n",
    "\n",
    "def extract_regex_spans(text: str) -> List[Dict[str, Any]]:\n",
    "    spans: List[Dict[str, Any]] = []\n",
    "\n",
    "    # UK phones (landline + +44 mobile)\n",
    "    for m in _UK_LANDLINE_RE.finditer(text):\n",
    "        spans.append({\n",
    "            \"start\": m.start(),\n",
    "            \"end\": m.end(),\n",
    "            \"label\": \"UK_PHONE_NUMBER\",\n",
    "            \"score\": 0.99,\n",
    "            \"source\": \"regex\",\n",
    "            \"original\": text[m.start():m.end()],\n",
    "        })\n",
    "    for m in _UK_MOBILE_INTL_RE.finditer(text):\n",
    "        spans.append({\n",
    "            \"start\": m.start(),\n",
    "            \"end\": m.end(),\n",
    "            \"label\": \"UK_PHONE_NUMBER\",\n",
    "            \"score\": 0.99,\n",
    "            \"source\": \"regex\",\n",
    "            \"original\": text[m.start():m.end()],\n",
    "        })\n",
    "\n",
    "    # IPv4\n",
    "    for m in _IPV4_RE.finditer(text):\n",
    "        s = m.group(0)\n",
    "        if not _is_valid_ipv4(s):\n",
    "            continue\n",
    "        spans.append({\n",
    "            \"start\": m.start(),\n",
    "            \"end\": m.end(),\n",
    "            \"label\": \"IP_ADDRESS\",\n",
    "            \"score\": 0.99,\n",
    "            \"source\": \"regex\",\n",
    "            \"original\": s,\n",
    "        })\n",
    "\n",
    "    # UK postcode (+ optional full-address line expansion)\n",
    "    for m in _UK_POSTCODE_RE.finditer(text):\n",
    "        spans.append({\n",
    "            \"start\": m.start(),\n",
    "            \"end\": m.end(),\n",
    "            \"label\": \"UK_POSTCODE\",\n",
    "            \"score\": 0.99,\n",
    "            \"source\": \"regex\",\n",
    "            \"original\": text[m.start():m.end()],\n",
    "        })\n",
    "        expanded = _expand_to_address_line(text, m.start(), m.end())\n",
    "        if expanded:\n",
    "            a_start, a_end = expanded\n",
    "            spans.append({\n",
    "                \"start\": a_start,\n",
    "                \"end\": a_end,\n",
    "                \"label\": \"UK_ADDRESS\",\n",
    "                \"score\": 0.97,\n",
    "                \"source\": \"regex\",\n",
    "                \"original\": text[a_start:a_end],\n",
    "            })\n",
    "\n",
    "    return spans\n",
    "\n",
    "def norm_spaces(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (s or \"\").strip())\n",
    "\n",
    "def norm_general(s: str) -> str:\n",
    "    s = (s or \"\").lower().strip()\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", s)\n",
    "\n",
    "def norm_digits(s: str) -> str:\n",
    "    return re.sub(r\"\\D+\", \"\", s or \"\")\n",
    "\n",
    "def norm_sort_code(s: str) -> str:\n",
    "    # 20-45-67, 204567 -> 204567\n",
    "    return re.sub(r\"[^0-9]+\", \"\", (s or \"\"))\n",
    "\n",
    "def norm_iban(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \"\", (s or \"\").upper().strip())\n",
    "\n",
    "def norm_phone(s: str) -> str:\n",
    "    # Keep digits and plus, remove spaces/punct\n",
    "    s = (s or \"\").strip()\n",
    "    s = re.sub(r\"[^\\d+]+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def normalise_for_key(label: str, value: str) -> str:\n",
    "    v = (value or \"\").strip()\n",
    "    if label == \"UK_SORT_CODE\":\n",
    "        return norm_sort_code(v)\n",
    "    if label == \"UK_ACCOUNT_NUMBER\":\n",
    "        return norm_digits(v)\n",
    "    if label == \"UK_IBAN\":\n",
    "        return norm_iban(v)\n",
    "    if label == \"CREDIT_CARD_NUMBER\":\n",
    "        return norm_digits(v)\n",
    "    if label == \"CARD_EXPIRY\":\n",
    "        return norm_general(v)  # \"08/27\" -> \"0827\"\n",
    "    if label == \"UK_PHONE_NUMBER\":\n",
    "        return norm_phone(v)\n",
    "    if label in {\"EMAIL_ADDRESS\", \"IP_ADDRESS\"}:\n",
    "        return norm_general(v)\n",
    "    return norm_spaces(v).lower()\n",
    "def luhn_check(number: str) -> bool:\n",
    "    digits = re.sub(r\"\\D+\", \"\", number)\n",
    "    if len(digits) < 13:\n",
    "        return False\n",
    "    total = 0\n",
    "    alt = False\n",
    "    for ch in digits[::-1]:\n",
    "        d = ord(ch) - 48\n",
    "        if alt:\n",
    "            d *= 2\n",
    "            if d > 9:\n",
    "                d -= 9\n",
    "        total += d\n",
    "        alt = not alt\n",
    "    return total % 10 == 0\n",
    "\n",
    "def iban_mod97(iban: str) -> bool:\n",
    "    \"\"\"\n",
    "    Basic IBAN mod-97 validation.\n",
    "    \"\"\"\n",
    "    s = re.sub(r\"\\s+\", \"\", iban).upper()\n",
    "    if len(s) < 15:\n",
    "        return False\n",
    "    # Move first 4 chars to end\n",
    "    rearr = s[4:] + s[:4]\n",
    "    # Convert letters to numbers A=10..Z=35\n",
    "    converted = \"\"\n",
    "    for ch in rearr:\n",
    "        if ch.isdigit():\n",
    "            converted += ch\n",
    "        elif \"A\" <= ch <= \"Z\":\n",
    "            converted += str(ord(ch) - ord(\"A\") + 10)\n",
    "        else:\n",
    "            return False\n",
    "    # mod 97 in chunks\n",
    "    remainder = 0\n",
    "    for i in range(0, len(converted), 9):\n",
    "        chunk = str(remainder) + converted[i:i+9]\n",
    "        remainder = int(chunk) % 97\n",
    "    return remainder == 1\n",
    "def apply_validators_and_adjust_score(label: str, value: str, base_score: float) -> float:\n",
    "    \"\"\"\n",
    "    Boost/penalise confidence based on validators.\n",
    "    \"\"\"\n",
    "    score = float(base_score)\n",
    "\n",
    "    if label == \"CREDIT_CARD_NUMBER\":\n",
    "        if luhn_check(value):\n",
    "            score = min(1.0, score + 0.08)\n",
    "        else:\n",
    "            score = max(0.0, score - 0.15)\n",
    "\n",
    "    if label == \"UK_IBAN\":\n",
    "        if iban_mod97(value):\n",
    "            score = min(1.0, score + 0.08)\n",
    "        else:\n",
    "            score = max(0.0, score - 0.20)\n",
    "\n",
    "    if label == \"UK_SORT_CODE\":\n",
    "        if len(norm_sort_code(value)) == 6:\n",
    "            score = min(1.0, score + 0.03)\n",
    "        else:\n",
    "            score = max(0.0, score - 0.10)\n",
    "\n",
    "    if label == \"UK_ACCOUNT_NUMBER\":\n",
    "        if len(norm_digits(value)) == 8:\n",
    "            score = min(1.0, score + 0.02)\n",
    "        else:\n",
    "            score = max(0.0, score - 0.10)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def assign_tags_and_mask(\n",
    "    text: str,\n",
    "    spans: List[Dict[str, Any]],\n",
    ") -> Tuple[str, Dict[str, str], Dict[str, float], List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Input spans must already be overlap-resolved and filtered.\n",
    "    Adds:\n",
    "      span[\"tag\"]\n",
    "    Returns:\n",
    "      masked_text, mapping(tag->original), scores(tag->confidence), spans(with tag)\n",
    "    \"\"\"\n",
    "    counters = defaultdict(int)\n",
    "    value_to_tag: Dict[Tuple[str, str], str] = {}   # (label, norm_value) -> tag\n",
    "    mapping: Dict[str, str] = {}\n",
    "    scores: Dict[str, float] = {}\n",
    "\n",
    "    # assign tags\n",
    "    for s in spans:\n",
    "        label = s[\"label\"]\n",
    "        original = s[\"original\"]\n",
    "        key = (label, normalise_for_key(label, original))\n",
    "\n",
    "        if key in value_to_tag:\n",
    "            tag = value_to_tag[key]\n",
    "        else:\n",
    "            counters[label] += 1\n",
    "            tag = f\"[{label}_{counters[label]}]\"\n",
    "            value_to_tag[key] = tag\n",
    "            mapping[tag] = original\n",
    "\n",
    "        # score: keep max across occurrences; adjust with validators\n",
    "        adj = apply_validators_and_adjust_score(label, original, float(s.get(\"score\", 0.0)))\n",
    "        scores[tag] = max(scores.get(tag, 0.0), adj)\n",
    "        s[\"tag\"] = tag\n",
    "        s[\"score\"] = adj\n",
    "\n",
    "    # replace from back to front\n",
    "    masked_text = text\n",
    "    for s in sorted(spans, key=lambda x: x[\"start\"], reverse=True):\n",
    "        masked_text = masked_text[:s[\"start\"]] + s[\"tag\"] + masked_text[s[\"end\"]:]  # type: ignore\n",
    "\n",
    "    return masked_text, mapping, scores, spans\n",
    "\n",
    "def resolve_overlaps_spans(\n",
    "    spans: List[Dict[str, Any]],\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    spans elements:\n",
    "      {start,end,label,score,source,original}\n",
    "    \"\"\"\n",
    "    spans_sorted = sorted(\n",
    "        spans,\n",
    "        key=lambda s: (\n",
    "            -PRIORITY.get(s[\"label\"], 0),\n",
    "            -(s[\"end\"] - s[\"start\"]),\n",
    "            -float(s.get(\"score\", 0.0)),\n",
    "            int(s[\"start\"]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    kept: List[Dict[str, Any]] = []\n",
    "    for s in spans_sorted:\n",
    "        overlaps = False\n",
    "        for k in kept:\n",
    "            if not (s[\"end\"] <= k[\"start\"] or s[\"start\"] >= k[\"end\"]):\n",
    "                overlaps = True\n",
    "                break\n",
    "        if not overlaps:\n",
    "            kept.append(s)\n",
    "\n",
    "    return sorted(kept, key=lambda s: s[\"start\"])\n",
    "\n",
    "def mask_with_gliner(\n",
    "    text: str,\n",
    "    model_name_or_obj: Any,\n",
    "    labels: Optional[List[str]] = None,\n",
    "    threshold: float = 0.5,\n",
    ") -> Tuple[str, Dict[str, str], Dict[str, float], List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Supports:\n",
    "    - model_name_or_obj: either a GLiNER instance or a model name string\n",
    "\n",
    "    Expected GLiNER output varies by version; we handle common patterns:\n",
    "    - list of dicts with keys: start, end, label, score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from gliner import GLiNER\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"GLiNER not installed. Run: pip install gliner\") from e\n",
    "\n",
    "    if isinstance(model_name_or_obj, str):\n",
    "        gliner = GLiNER.from_pretrained(model_name_or_obj)\n",
    "    else:\n",
    "        gliner = model_name_or_obj\n",
    "\n",
    "    # If you don't pass labels, use canonical-ish ones (edit for your project)\n",
    "    if labels is None:\n",
    "        labels = [\n",
    "            \"person\", \"organization\",\n",
    "            \"email_address\", \"phone_number\", \"ip_address\",\n",
    "            \"date\",\n",
    "            \"address\", \"street_address\",\n",
    "            \"location\",\n",
    "            \"postcode\",\n",
    "            \"uk_iban\", \"sort_code\", \"account_number\",\n",
    "            \"credit_card_number\", \"card_expiry\",\n",
    "            \"transaction_id\", \"support_ticket_number\",\n",
    "            \"session_id\", \"customer_reference\", \"account_id\",\n",
    "]\n",
    "    preds = gliner.predict_entities(text, labels, threshold=threshold)\n",
    "\n",
    "    spans: List[Dict[str, Any]] = []\n",
    "    for p in preds:\n",
    "        raw_label = str(p.get(\"label\", \"\")).strip()\n",
    "        canon = GLINER_TO_CANON.get(raw_label.lower(), GLINER_TO_CANON.get(raw_label, None))\n",
    "        if not canon:\n",
    "            continue\n",
    "        if canon not in ALLOWED_CANON:\n",
    "            continue\n",
    "\n",
    "        start = int(p[\"start\"])\n",
    "        end = int(p[\"end\"])\n",
    "        original = text[start:end]\n",
    "        spans.append({\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"label\": canon,\n",
    "            \"score\": float(p.get(\"score\", 0.0)),\n",
    "            \"source\": \"gliner\",\n",
    "            \"original\": original,\n",
    "})\n",
    "\n",
    "    # Add deterministic regex spans to cover common GLiNER misses\n",
    "    spans.extend(extract_regex_spans(text))\n",
    "\n",
    "    spans = resolve_overlaps_spans(spans)\n",
    "    return assign_tags_and_mask(text, spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8982e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a stable reference to the original regex extractor (v1) before adding more patterns\n",
    "# This prevents recursion if we later override `extract_regex_spans`.\n",
    "extract_regex_spans_v1 = extract_regex_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5977e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extra regex backstops: email + dates (incl DOB) ---\n",
    "import datetime\n",
    "\n",
    "_EMAIL_RE = re.compile(\n",
    "    r\"(?<![\\w.+-])([A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,})(?![\\w.+-])\",\n",
    "    re.IGNORECASE,\n",
    " )\n",
    "\n",
    "_DOB_CONTEXT_RE = re.compile(r\"\\bDOB\\b|\\bD\\.?O\\.?B\\.?\\b|date\\s+of\\s+birth|\\bborn\\b\", re.IGNORECASE)\n",
    "\n",
    "# 12 March 1990 / 17 February 1989 etc.\n",
    "_DATE_TEXT_RE = re.compile(\n",
    "    r\"\\b(?P<day>\\d{1,2})\\s+\"\n",
    "    r\"(?P<mon>jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|\"\n",
    "    r\"jul(?:y)?|aug(?:ust)?|sep(?:t|tember)?|oct(?:ober)?|nov(?:ember)?|dec(?:ember)?)\\s+\"\n",
    "    r\"(?P<year>\\d{4})\\b\",\n",
    "    re.IGNORECASE,\n",
    " )\n",
    "\n",
    "# 21/12/2025, 21-12-2025, 21.12.2025 (kept strict: requires year)\n",
    "_DATE_NUMERIC_RE = re.compile(\n",
    "    r\"\\b(?P<day>\\d{1,2})[\\/\\-.](?P<mon>\\d{1,2})[\\/\\-.](?P<year>\\d{4})\\b\"\n",
    " )\n",
    "\n",
    "_MONTH_MAP = {\n",
    "    \"jan\": 1, \"january\": 1,\n",
    "    \"feb\": 2, \"february\": 2,\n",
    "    \"mar\": 3, \"march\": 3,\n",
    "    \"apr\": 4, \"april\": 4,\n",
    "    \"may\": 5,\n",
    "    \"jun\": 6, \"june\": 6,\n",
    "    \"jul\": 7, \"july\": 7,\n",
    "    \"aug\": 8, \"august\": 8,\n",
    "    \"sep\": 9, \"sept\": 9, \"september\": 9,\n",
    "    \"oct\": 10, \"october\": 10,\n",
    "    \"nov\": 11, \"november\": 11,\n",
    "    \"dec\": 12, \"december\": 12,\n",
    "}\n",
    "\n",
    "def _is_valid_date_parts(year: int, month: int, day: int) -> bool:\n",
    "    if year < 1900 or year > 2100:\n",
    "        return False\n",
    "    try:\n",
    "        datetime.date(year, month, day)\n",
    "    except Exception:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _date_label_for_match(text: str, start: int, end: int) -> str:\n",
    "    # If \"DOB\" appears nearby, treat it as DATE_OF_BIRTH; else DATE\n",
    "    left = text[max(0, start - 40):start]\n",
    "    right = text[end:min(len(text), end + 25)]\n",
    "    ctx = left + \" \" + right\n",
    "    return \"DATE_OF_BIRTH\" if _DOB_CONTEXT_RE.search(ctx) else \"DATE\"\n",
    "\n",
    "def extract_regex_spans_v2(text: str) -> List[Dict[str, Any]]:\n",
    "    # Start with existing regex extraction (phones, IPs, postcodes, address expansion)\n",
    "    # IMPORTANT: use v1 reference to avoid recursion\n",
    "    spans = extract_regex_spans_v1(text)\n",
    "\n",
    "    # Emails\n",
    "    for m in _EMAIL_RE.finditer(text):\n",
    "        email = m.group(1)\n",
    "        spans.append({\n",
    "            \"start\": m.start(1),\n",
    "            \"end\": m.end(1),\n",
    "            \"label\": \"EMAIL_ADDRESS\",\n",
    "            \"score\": 0.99,\n",
    "            \"source\": \"regex\",\n",
    "            \"original\": email,\n",
    "        })\n",
    "\n",
    "    # Dates (month name)\n",
    "    for m in _DATE_TEXT_RE.finditer(text):\n",
    "        day = int(m.group(\"day\"))\n",
    "        mon_raw = m.group(\"mon\").lower()\n",
    "        month = _MONTH_MAP.get(mon_raw, _MONTH_MAP.get(mon_raw[:3], 0))\n",
    "        year = int(m.group(\"year\"))\n",
    "        if month and _is_valid_date_parts(year, month, day):\n",
    "            start, end = m.start(), m.end()\n",
    "            spans.append({\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "                \"label\": _date_label_for_match(text, start, end),\n",
    "                \"score\": 0.97,\n",
    "                \"source\": \"regex\",\n",
    "                \"original\": text[start:end],\n",
    "            })\n",
    "\n",
    "    # Dates (numeric with year)\n",
    "    for m in _DATE_NUMERIC_RE.finditer(text):\n",
    "        day = int(m.group(\"day\"))\n",
    "        month = int(m.group(\"mon\"))\n",
    "        year = int(m.group(\"year\"))\n",
    "        if _is_valid_date_parts(year, month, day):\n",
    "            start, end = m.start(), m.end()\n",
    "            spans.append({\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "                \"label\": _date_label_for_match(text, start, end),\n",
    "                \"score\": 0.97,\n",
    "                \"source\": \"regex\",\n",
    "                \"original\": text[start:end],\n",
    "            })\n",
    "\n",
    "    # Re-resolve overlaps after adding more spans\n",
    "    spans = resolve_overlaps_spans(spans)\n",
    "    return spans\n",
    "\n",
    "# Make mask_with_gliner() pick up the newer extractor\n",
    "extract_regex_spans = extract_regex_spans_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1edabe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    s = (s or \"\").lower().strip()\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", s)\n",
    "\n",
    "def _sim(a: str, b: str) -> float:\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def _match_score(exp: str, found: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns a match score in [0,1]:\n",
    "    - exact => 1.0\n",
    "    - containment (>=6 chars) => 0.95\n",
    "    - else SequenceMatcher similarity\n",
    "    \"\"\"\n",
    "    e = _norm(exp)\n",
    "    f = _norm(found)\n",
    "    if not e or not f:\n",
    "        return 0.0\n",
    "    if e == f:\n",
    "        return 1.0\n",
    "    shorter, longer = (e, f) if len(e) <= len(f) else (f, e)\n",
    "    if len(shorter) >= 6 and shorter in longer:\n",
    "        return 0.95\n",
    "    return _sim(e, f)\n",
    "\n",
    "def build_found_typed(mapping: dict) -> dict:\n",
    "    \"\"\"\n",
    "    mapping: { \"[LABEL_1]\": \"original value\", ... }\n",
    "    returns: { \"LABEL\": {values...} }\n",
    "    \"\"\"\n",
    "    out = defaultdict(set)\n",
    "    for tag, val in mapping.items():\n",
    "        label = tag.strip(\"[]\").rsplit(\"_\", 1)[0]\n",
    "        out[label].add(val)\n",
    "    return out\n",
    "def score_run_typed(mapping: dict, expected_typed: dict, sim_threshold: float = 0.88) -> dict:\n",
    "    \"\"\"\n",
    "    Computes:\n",
    "      - recall (% expected items matched to some found item, lenient)\n",
    "      - type_accuracy (% of matched expected items with correct predicted type)\n",
    "      - overall (= recall * type_accuracy)\n",
    "      - false_positives_total (count of found items not matched to ANY expected)\n",
    "      - false_positives_by_type (dict label -> count)\n",
    "    \"\"\"\n",
    "    found_typed = build_found_typed(mapping)\n",
    "\n",
    "    # Flatten expected (type,value)\n",
    "    expected_pairs = [(label, v) for label, vals in expected_typed.items() for v in vals]\n",
    "    total_expected = len(expected_pairs)\n",
    "\n",
    "    # Flatten found (type,value)\n",
    "    found_pairs = [(label, v) for label, vals in found_typed.items() for v in vals]\n",
    "\n",
    "    matched_found = set()\n",
    "    matched_expected = set()\n",
    "    correct_type_hits = 0\n",
    "\n",
    "    # Reserved matching: each found can match at most one expected\n",
    "    for i, (exp_label, exp_val) in enumerate(expected_pairs):\n",
    "        best_j = None\n",
    "        best_score = -1.0\n",
    "        best_type_ok = False\n",
    "\n",
    "        for j, (found_label, found_val) in enumerate(found_pairs):\n",
    "            if j in matched_found:\n",
    "                continue\n",
    "            score = _match_score(exp_val, found_val)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_j = j\n",
    "                best_type_ok = (found_label == exp_label)\n",
    "\n",
    "        if best_j is not None and best_score >= sim_threshold:\n",
    "            matched_expected.add(i)\n",
    "            matched_found.add(best_j)\n",
    "            if best_type_ok:\n",
    "                correct_type_hits += 1\n",
    "\n",
    "    recall = len(matched_expected) / max(1, total_expected)\n",
    "    type_acc = (correct_type_hits / len(matched_expected)) if matched_expected else 0.0\n",
    "    overall = recall * type_acc\n",
    "\n",
    "    # False positives = found pairs not used in any match\n",
    "    fp_by_type = defaultdict(int)\n",
    "    fp_total = 0\n",
    "    for j, (found_label, found_val) in enumerate(found_pairs):\n",
    "        if j not in matched_found:\n",
    "            fp_total += 1\n",
    "            fp_by_type[found_label] += 1\n",
    "\n",
    "    return {\n",
    "        \"recall\": recall * 100.0,\n",
    "        \"type_accuracy\": type_acc * 100.0,\n",
    "        \"overall\": overall * 100.0,\n",
    "        \"found_count\": len(found_pairs),\n",
    "        \"expected_count\": total_expected,\n",
    "        \"false_positives_total\": fp_total,\n",
    "        \"false_positives_by_type\": dict(fp_by_type),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6843f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLiNER\n",
    "def print_scores(name: str, s: dict, show_fp_types: bool = True, top_k: int = 12):\n",
    "    print(\n",
    "        f\"{name:<10} | \"\n",
    "        f\"Recall: {s['recall']:.1f}% | \"\n",
    "        f\"TypeAcc: {s['type_accuracy']:.1f}% | \"\n",
    "        f\"Overall: {s['overall']:.1f}% | \"\n",
    "        f\"FP: {s['false_positives_total']} \"\n",
    "        f\"(found {s['found_count']}, expected {s['expected_count']})\"\n",
    "    )\n",
    "    if show_fp_types and s[\"false_positives_total\"] > 0:\n",
    "        fp = s[\"false_positives_by_type\"]\n",
    "        # sort by count desc, then label\n",
    "        items = sorted(fp.items(), key=lambda kv: (-kv[1], kv[0]))[:top_k]\n",
    "        fp_str = \", \".join([f\"{k}:{v}\" for k, v in items])\n",
    "        print(f\"   FP by type: {fp_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac4ad33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518db74d4bff4407b185092a13df5371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14 tests from G:\\Proxyon\\Test\\tests.json\n",
      "Model: urchade/gliner_multi_pii-v1 | threshold=0.1\n",
      "-\n",
      "sample_1   | Recall: 100.0% | TypeAcc: 92.3% | Overall: 92.3% | FP: 0 (found 26, expected 26)\n",
      "sample_2   | Recall: 96.2% | TypeAcc: 88.0% | Overall: 84.6% | FP: 0 (found 25, expected 26)\n",
      "sample_3   | Recall: 92.3% | TypeAcc: 95.8% | Overall: 88.5% | FP: 1 (found 25, expected 26)\n",
      "   FP by type: CARD_EXPIRY:1\n",
      "sample_3   | Recall: 92.3% | TypeAcc: 95.8% | Overall: 88.5% | FP: 1 (found 25, expected 26)\n",
      "   FP by type: CARD_EXPIRY:1\n",
      "sample_4   | Recall: 83.3% | TypeAcc: 85.0% | Overall: 70.8% | FP: 0 (found 20, expected 24)\n",
      "sample_5   | Recall: 88.9% | TypeAcc: 81.2% | Overall: 72.2% | FP: 1 (found 17, expected 18)\n",
      "   FP by type: ORG:1\n",
      "sample_6   | Recall: 80.0% | TypeAcc: 93.8% | Overall: 75.0% | FP: 0 (found 16, expected 20)\n",
      "sample_7   | Recall: 88.2% | TypeAcc: 100.0% | Overall: 88.2% | FP: 0 (found 15, expected 17)\n",
      "sample_8   | Recall: 82.4% | TypeAcc: 100.0% | Overall: 82.4% | FP: 1 (found 15, expected 17)\n",
      "   FP by type: UK_POSTCODE:1\n",
      "sample_9   | Recall: 89.5% | TypeAcc: 100.0% | Overall: 89.5% | FP: 0 (found 17, expected 19)\n",
      "sample_10  | Recall: 77.8% | TypeAcc: 92.9% | Overall: 72.2% | FP: 1 (found 15, expected 18)\n",
      "   FP by type: PERSON:1\n",
      "sample_11  | Recall: 72.2% | TypeAcc: 76.9% | Overall: 55.6% | FP: 0 (found 13, expected 18)\n",
      "sample_12  | Recall: 83.3% | TypeAcc: 80.0% | Overall: 66.7% | FP: 0 (found 15, expected 18)\n",
      "sample_13  | Recall: 82.4% | TypeAcc: 85.7% | Overall: 70.6% | FP: 0 (found 14, expected 17)\n",
      "=\n",
      "AVG        | Recall: 86.3% | TypeAcc: 90.5% | Overall: 78.4% | FP: 5 (found 258, expected 290)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "def load_tests_bundle(path: str | Path = \"tests.json\") -> Dict[str, Any]:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Could not find {p.resolve()}\")\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        bundle = json.load(f)\n",
    "    if not isinstance(bundle, dict) or \"tests\" not in bundle:\n",
    "        raise ValueError(f\"Unexpected format in {p}\")\n",
    "    return bundle\n",
    "\n",
    "def expected_typed_to_sets(expected_typed: Dict[str, List[str]]) -> Dict[str, set]:\n",
    "    # stored as JSON lists; scorer works with any iterable, but sets are convenient\n",
    "    out: Dict[str, set] = {}\n",
    "    for label, values in (expected_typed or {}).items():\n",
    "        out[label] = set(values or [])\n",
    "    return out\n",
    "\n",
    "def run_tests_from_json(\n",
    "    model_name: str = \"urchade/gliner_multi_pii-v1\",\n",
    "    path: str | Path = \"tests.json\",\n",
    "    threshold: float = 0.5,\n",
    "    show_masked_text: bool = False,\n",
    "    limit: int | None = None,\n",
    ") -> List[Tuple[str, dict, str]]:\n",
    "    bundle = load_tests_bundle(path)\n",
    "    tests = bundle.get(\"tests\", [])\n",
    "    if not isinstance(tests, list):\n",
    "        raise ValueError(\"bundle['tests'] must be a list\")\n",
    "\n",
    "    try:\n",
    "        from gliner import GLiNER\n",
    "    except RuntimeError as e:\n",
    "        msg = str(e)\n",
    "        if \"TORCH_LIBRARY\" in msg and \"prims\" in msg:\n",
    "            raise RuntimeError(\n",
    "                \"PyTorch is in a corrupted import state (duplicate prims registration). \"\n",
    "                \"In VS Code: restart the notebook kernel, then run cells 1→6 again. \"\n",
    "                \"Also avoid installing/upgrading torch while the kernel is running.\"\n",
    "            ) from e\n",
    "        raise\n",
    "    model = GLiNER.from_pretrained(model_name)\n",
    "\n",
    "    if limit is not None:\n",
    "        tests = tests[: int(limit)]\n",
    "\n",
    "    results: List[Tuple[str, dict, str]] = []\n",
    "    print(f\"Loaded {len(tests)} tests from {Path(path).resolve()}\")\n",
    "    print(f\"Model: {model_name} | threshold={threshold}\")\n",
    "    print(\"-\")\n",
    "\n",
    "    for t in tests:\n",
    "        test_id = str(t.get(\"id\", \"<no-id>\"))\n",
    "        text = str(t.get(\"text\", \"\"))\n",
    "        expected_typed_raw = t.get(\"expected_typed\", {}) or {}\n",
    "        expected_typed = expected_typed_to_sets(expected_typed_raw)\n",
    "\n",
    "        masked_text, mapping, scores, spans = mask_with_gliner(\n",
    "            text=text,\n",
    "            model_name_or_obj=model,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "        s = score_run_typed(mapping=mapping, expected_typed=expected_typed)\n",
    "        print_scores(test_id, s)\n",
    "        if show_masked_text:\n",
    "            print(\"Masked text:\")\n",
    "            print(masked_text)\n",
    "            print(\"-\")\n",
    "        results.append((test_id, s, masked_text,mapping))\n",
    "\n",
    "    # Simple aggregate (macro average)\n",
    "    if results:\n",
    "        avg = {\n",
    "            \"recall\": sum(r[1][\"recall\"] for r in results) / len(results),\n",
    "            \"type_accuracy\": sum(r[1][\"type_accuracy\"] for r in results) / len(results),\n",
    "            \"overall\": sum(r[1][\"overall\"] for r in results) / len(results),\n",
    "            \"false_positives_total\": sum(r[1][\"false_positives_total\"] for r in results),\n",
    "            \"found_count\": sum(r[1][\"found_count\"] for r in results),\n",
    "            \"expected_count\": sum(r[1][\"expected_count\"] for r in results),\n",
    "            \"false_positives_by_type\": {},\n",
    "        }\n",
    "        print(\"=\")\n",
    "        print_scores(\"AVG\", avg, show_fp_types=False)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run all saved tests\n",
    "_results = run_tests_from_json(path=\"tests.json\", threshold=0.1, show_masked_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72dc0c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = load_tests_bundle(path=\"tests.json\").get(\"tests\", [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9c69a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE: Onboarding\n",
      "agent SB\n",
      "\n",
      "Applicant name: George A. Patel\n",
      "DOB 01/06/1990\n",
      "\n",
      "Employer org: Westmoor Consulting Group\n",
      "\n",
      "Address:\n",
      "21 Orchard Way, Reading RG2 9QF\n",
      "\n",
      "Email george.patel@westmoor-group.co.uk\n",
      "Phone 0118 992 7744\n",
      "\n",
      "IP logged 51.140.77.9\n",
      "Session sess_113a9cfe\n",
      "\n",
      "Account verification via £1 test card\n",
      "Card 4000 1234 5678 9010 exp 04/28\n",
      "\n",
      "Refs\n",
      "TRX-2026-01-16-441002\n",
      "CUST-REF-UK-440771\n",
      "SUP-440771\n",
      "ACC-2200441\n",
      "INT-EE120\n",
      "\n",
      "Welcome email sent 16 January 2026\n",
      "---- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked -------- Masked ----\n",
      "{'[PERSON_1]': 'George A. Patel', '[DATE_OF_BIRTH_1]': '01/06/1990', '[ORG_1]': 'Westmoor Consulting Group', '[UK_ADDRESS_1]': '21 Orchard Way, Reading RG2 9QF', '[EMAIL_ADDRESS_1]': 'george.patel@westmoor-group.co.uk', '[UK_PHONE_NUMBER_1]': '0118 992 7744', '[IP_ADDRESS_1]': '51.140.77.9', '[SESSION_ID_1]': 'sess_113a9cfe', '[CREDIT_CARD_NUMBER_1]': '4000 1234 5678 9010', '[CARD_EXPIRY_1]': '04/28', '[CUSTOMER_REFERENCE_1]': 'TRX-2026-01-16-441002', '[ACCOUNT_ID_1]': 'CUST-REF-UK-440771', '[SUPPORT_TICKET_NUMBER_1]': 'SUP-440771\\nACC-2200441\\nINT-EE120', '[DATE_1]': '16 January 2026'}\n",
      "QUEUE: Onboarding\n",
      "agent SB\n",
      "\n",
      "Applicant name: [PERSON_1]\n",
      "DOB [DATE_OF_BIRTH_1]\n",
      "\n",
      "Employer org: [ORG_1]\n",
      "\n",
      "Address:\n",
      "[UK_ADDRESS_1]\n",
      "\n",
      "Email [EMAIL_ADDRESS_1]\n",
      "Phone [UK_PHONE_NUMBER_1]\n",
      "\n",
      "IP logged [IP_ADDRESS_1]\n",
      "Session [SESSION_ID_1]\n",
      "\n",
      "Account verification via £1 test card\n",
      "Card [CREDIT_CARD_NUMBER_1] exp [CARD_EXPIRY_1]\n",
      "\n",
      "Refs\n",
      "[CUSTOMER_REFERENCE_1]\n",
      "[ACCOUNT_ID_1]\n",
      "[SUPPORT_TICKET_NUMBER_1]\n",
      "\n",
      "Welcome email sent [DATE_1]\n"
     ]
    }
   ],
   "source": [
    "test_num = 13\n",
    "print(tests[test_num][\"text\"])#\n",
    "print(20 * \"---- Masked ----\")\n",
    "print(_results[test_num][3])\n",
    "print(_results[test_num][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3429eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case note (KYC + Support) created by [PERSON_1]. DOB confirmed as [DATE_OF_BIRTH_1].\n",
      "\n",
      "Primary contact email: [EMAIL_ADDRESS_1]; backup: [EMAIL_ADDRESS_2].\n",
      "\n",
      "Customer reachable on [UK_PHONE_NUMBER_1] (mobile) and [UK_PHONE_NUMBER_2] (desk).\n",
      "Alt number seen in legacy CRM: [UK_IBAN_1].\n",
      "\n",
      "Address verified via proof of residence:\n",
      "[UK_ADDRESS_1]\n",
      "\n",
      "Login activity: current IP [IP_ADDRESS_1]; prior IP [IP_ADDRESS_2].\n",
      "\n",
      "Bank details for refunds: bank [ORG_1], sort code [UK_SORT_CODE_1], account number [UK_ACCOUNT_NUMBER_1].\n",
      "IBAN used for international transfers: [UK_IBAN_2].\n",
      "\n",
      "Payment method update: Visa 4242 4242 4242 4242 and Mastercard [CREDIT_CARD_NUMBER_1] stored; expiry [CARD_EXPIRY_1].\n",
      "Note: customer mentioned “card ending [CARD_EXPIRY_2]” during the call.\n",
      "\n",
      "Timeline: verification completed on [DATE_1].\n",
      "Transaction refs: [TRANSACTION_ID_1] and [TRANSACTION_ID_2].\n",
      "\n",
      "Internal refs include ACCOUNT_ID [ACCOUNT_ID_1], CUSTOMER_REF [CUSTOMER_REFERENCE_1], session [SESSION_ID_1], and internal id INT-UK-004291.\n",
      "Support ticket [SUPPORT_TICKET_NUMBER_1] raised regarding merchant [ORG_2]\n",
      "--------------------------------------------------\n",
      "QUEUE: KYC  |  STATUS: pending docs\n",
      "Agent: HM\n",
      "\n",
      "Caller says name on account is [PERSON_1] (sometimes shows as [PERSON_2] in older CRM)\n",
      "DOB: [DATE_OF_BIRTH_1]\n",
      "\n",
      "Address on file:\n",
      "[UK_ADDRESS_1]\n",
      "United Kingdom\n",
      "\n",
      "Contact:\n",
      "Email: [EMAIL_ADDRESS_1]\n",
      "Phone (mobile): [UK_PHONE_NUMBER_1]\n",
      "Alt landline: [UK_PHONE_NUMBER_2]\n",
      "\n",
      "Login/IP notes: successful login from [IP_ADDRESS_1]; prior attempt from [IP_ADDRESS_2] (internal)\n",
      "Session: [SESSION_ID_1]\n",
      "\n",
      "Banking:\n",
      "Sort code [UK_SORT_CODE_1]  |  Acct [UK_ACCOUNT_NUMBER_1]\n",
      "IBAN: [UK_IBAN_1]\n",
      "\n",
      "Card used for verification: [CARD_EXPIRY_1]  exp [CARD_EXPIRY_2]\n",
      "\n",
      "Refs:\n",
      "TXN: [TRANSACTION_ID_1]\n",
      "Cust ref: [CUSTOMER_REFERENCE_1]\n",
      "Ticket: [SUPPORT_TICKET_NUMBER_1]\n",
      "Account ID: [ACCOUNT_ID_1]\n",
      "Internal ID: [UK_ACCOUNT_NUMBER_2]\n",
      "\n",
      "Action: asked for proof of addr, told customer to reply to CASE-UPDATE thread.\n",
      "--------------------------------------------------\n",
      "CASE-UPDATE // 14/01 09:17\n",
      "Agent initials: [ORG_1] on merchant descriptor: [ORG_2] (customer says it appears as [ORG_3])\n",
      "Customer: [PERSON_1]\n",
      "\n",
      "Issue: chargeback request re: card payment.\n",
      "Card: [CREDIT_CARD_NUMBER_1]  expiry [CARD_EXPIRY_1]\n",
      "Transaction ref: [TRANSACTION_ID_1]\n",
      "\n",
      "Customer reference: [CUSTOMER_REFERENCE_1]\n",
      "Support ticket: [SUPPORT_TICKET_NUMBER_1]\n",
      "Account: [UK_ACCOUNT_NUMBER_1]  ([UK_ACCOUNT_NUMBER_2])\n",
      "\n",
      "Contact details:\n",
      "email [EMAIL_ADDRESS_1]\n",
      "phone [UK_PHONE_NUMBER_1]\n",
      "\n",
      "Address confirmed on call:\n",
      "[UK_ADDRESS_1]\n",
      "\n",
      "Auth/session logs: [SESSION_ID_1]; IP [IP_ADDRESS_1]\n",
      "\n",
      "Notes: advised 10 working days + sent template letter dated [DATE_1].\n",
      "--------------------------------------------------\n",
      "STATUS: resolved   QUEUE: Billing\n",
      "agent: KL\n",
      "\n",
      "Spoke to: [PERSON_1]\n",
      "Confirmed DOB on security: [DATE_OF_BIRTH_1]\n",
      "\n",
      "Move-in address for correspondence (temp):\n",
      "[UK_ADDRESS_1]\n",
      "\n",
      "Also mentions work location: [LOCATION_1]\n",
      "\n",
      "Contact:\n",
      "[EMAIL_ADDRESS_1]\n",
      "[UK_PHONE_NUMBER_1]\n",
      "\n",
      "Network logs show login from IP [IP_ADDRESS_1]\n",
      "Session id: [SESSION_ID_1]\n",
      "\n",
      "Bank details for refund:\n",
      "Sort code: [UK_SORT_CODE_1]\n",
      "Account number: [UK_ACCOUNT_NUMBER_1]\n",
      "IBAN entered: [UK_IBAN_1]\n",
      "\n",
      "Refund refs:\n",
      "Transaction ID [TRANSACTION_ID_1]\n",
      "Customer ref [CUSTOMER_REFERENCE_1]\n",
      "Ticket [SUPPORT_TICKET_NUMBER_1]\n",
      "Account ID [ACCOUNT_ID_1]\n",
      "Internal ID INT-2D19B\n",
      "\n",
      "Outcome: refund initiated [DATE_1] and email sent.\n",
      "--------------------------------------------------\n",
      " QUEUE: Fraud Review (manual)\n",
      "Agent: TB\n",
      "\n",
      "Name reported on statement: [PERSON_1]\n",
      "Organisation involved (beneficiary): [ORG_1]\n",
      "\n",
      "Customer says they never authorised bank transfer.\n",
      "\n",
      "Address verified:\n",
      "[UK_ADDRESS_1]\n",
      "\n",
      "Email on file [EMAIL_ADDRESS_1]\n",
      "Phone: [UK_PHONE_NUMBER_1]\n",
      "\n",
      "IP from suspicious login: [IP_ADDRESS_1]\n",
      "Session: [SESSION_ID_1]\n",
      "\n",
      "Banking identifiers captured in chat transcript:\n",
      "Sort code [UK_SORT_CODE_1]\n",
      "Account number [UK_ACCOUNT_NUMBER_1]\n",
      "IBAN: [UK_IBAN_1]\n",
      "\n",
      "Refs:\n",
      "Transaction ID [TRANSACTION_ID_1]\n",
      "Customer reference [CUSTOMER_REFERENCE_1]\n",
      "Support ticket number [SUPPORT_TICKET_NUMBER_1]\n",
      "Account ID [ACCOUNT_ID_1]\n",
      "Internal ID INT-7F31D\n",
      "\n",
      "Date letter issued: [DATE_1]\n",
      "--------------------------------------------------\n",
      "  QUEUE: Onboarding  |  STATUS: awaiting signature\n",
      "Agent: JW\n",
      "\n",
      "Customer details entered:\n",
      "Name: [PERSON_1]\n",
      "DOB (from ID check): [DATE_OF_BIRTH_1]\n",
      "Employer/Org: [ORG_1]\n",
      "\n",
      "Home address:\n",
      "[UK_ADDRESS_1]\n",
      "\n",
      "Contact:\n",
      "[EMAIL_ADDRESS_1]\n",
      "\n",
      "Technical:\n",
      "IP seen at registration: [IP_ADDRESS_1]\n",
      "Session ID: [SESSION_ID_1]\n",
      "\n",
      "Payment method for £1 verification:\n",
      "Card number [CREDIT_CARD_NUMBER_1]  exp [CARD_EXPIRY_1]\n",
      "\n",
      "Account setup refs:\n",
      "Customer reference: [CUSTOMER_REFERENCE_1]\n",
      "Support ticket: [SUPPORT_TICKET_NUMBER_1]\n",
      "Account ID: [ACCOUNT_ID_1]\n",
      "Internal ID: INT-1B77E\n",
      "Transaction ID: [TRANSACTION_ID_1]\n",
      "\n",
      "Note: welcome email sent [DATE_1]; asked customer to confirm postcode [UK_POSTCODE_1] matches bank statement.\n",
      "--------------------------------------------------\n",
      "[DATE_1]   QUEUE: Payments   STATUS: escalated\n",
      "agent: RP\n",
      "\n",
      "Customer name showing on portal: [PERSON_1]\n",
      "Alt spelling in email trail: [PERSON_2]\n",
      "\n",
      "DOB used for security: [DATE_OF_BIRTH_1]\n",
      "\n",
      "Billing address:\n",
      "[UK_ADDRESS_1]\n",
      "\n",
      "Contact\n",
      "[EMAIL_ADDRESS_1]\n",
      "\n",
      "Login trail: IP [IP_ADDRESS_1], earlier [IP_ADDRESS_2]\n",
      "Session = [SESSION_ID_1]\n",
      "\n",
      "Bank details captured:\n",
      "Sort Code [UK_SORT_CODE_1]\n",
      "Account [UK_ACCOUNT_NUMBER_1]\n",
      "IBAN [UK_IBAN_1]\n",
      "\n",
      "Refs\n",
      "Transaction [TRANSACTION_ID_1]\n",
      "Customer ref [CUSTOMER_REFERENCE_1]\n",
      "Ticket [SUPPORT_TICKET_NUMBER_1]\n",
      "Account [ACCOUNT_ID_1]\n",
      "Internal INT-77AC3\n",
      "\n",
      "Note: user claims refund email sent [DATE_2].\n",
      "--------------------------------------------------\n",
      "CASE-UPDATE 16/01 15:04\n",
      "[PERSON_1]\n",
      "\n",
      "Merchant name: [ORG_1]\n",
      "Customer: [PERSON_2]\n",
      "\n",
      "Card used [CREDIT_CARD_NUMBER_1] exp [CARD_EXPIRY_1]\n",
      "Transaction ref [TRANSACTION_ID_1]\n",
      "\n",
      "Address confirmed:\n",
      "[UK_ADDRESS_1]\n",
      "\n",
      "Email [EMAIL_ADDRESS_1]\n",
      "Phone [UK_PHONE_NUMBER_1]\n",
      "\n",
      "IP during payment: [IP_ADDRESS_1]\n",
      "Session [SESSION_ID_1]\n",
      "\n",
      "Customer ref [CUSTOMER_REFERENCE_1]\n",
      "Ticket [SUPPORT_TICKET_NUMBER_1]\n",
      "Account [ACCOUNT_ID_1]\n",
      "Internal ID INT-BC712\n",
      "\n",
      "Letter issued [DATE_1].\n",
      "--------------------------------------------------\n",
      "QUEUE: KYC\n",
      "Agent: LS\n",
      "\n",
      "Name on application: [PERSON_1]\n",
      "\n",
      "DOB: 1994/11/03\n",
      "\n",
      "Home address:\n",
      "[UK_ADDRESS_1]\n",
      "\n",
      "Contact [EMAIL_ADDRESS_1]\n",
      "Phone [UK_PHONE_NUMBER_1]\n",
      "\n",
      "IP check [IP_ADDRESS_1]\n",
      "Session [SESSION_ID_1]\n",
      "\n",
      "Bank info submitted:\n",
      "Sort code [UK_SORT_CODE_1]\n",
      "Account number [UK_ACCOUNT_NUMBER_1]\n",
      "IBAN [UK_IBAN_1]\n",
      "\n",
      "Refs\n",
      "Transaction [SESSION_ID_2]\n",
      "Customer [CUSTOMER_REFERENCE_1]\n",
      "Ticket [SUPPORT_TICKET_NUMBER_1]\n",
      "Account [UK_ACCOUNT_NUMBER_2]\n",
      "Internal INT-091AF\n",
      "--------------------------------------------------\n",
      "Fraud note 16/01 19:33\n",
      "agent ID: PL\n",
      "\n",
      "Customer: [PERSON_1]\n",
      "\n",
      "Suspicious merchant: [ORG_1] [UK_ACCOUNT_NUMBER_1] exp [CARD_EXPIRY_1]\n",
      "Transaction ID [TRANSACTION_ID_1]\n",
      "\n",
      "Customer email [EMAIL_ADDRESS_1]\n",
      "Phone [UK_PHONE_NUMBER_1]\n",
      "\n",
      "Address [UK_ADDRESS_1]\n",
      "\n",
      "IP [IP_ADDRESS_1]\n",
      "Session [SESSION_ID_1]\n",
      "\n",
      "Customer ref [CUSTOMER_REFERENCE_1]\n",
      "Ticket [SUPPORT_TICKET_NUMBER_1]\n",
      "Account [ACCOUNT_ID_1]\n",
      "Internal [UK_ACCOUNT_NUMBER_2]\n",
      "\n",
      "Letter dated [DATE_1]\n",
      "--------------------------------------------------\n",
      "QUEUE: Onboarding\n",
      "agent SB\n",
      "\n",
      "Applicant name: [PERSON_1]\n",
      "DOB [DATE_OF_BIRTH_1]\n",
      "\n",
      "Employer org: [ORG_1]\n",
      "\n",
      "Address:\n",
      "[UK_ADDRESS_1]\n",
      "\n",
      "Email [EMAIL_ADDRESS_1]\n",
      "Phone [UK_PHONE_NUMBER_1]\n",
      "\n",
      "IP logged [IP_ADDRESS_1]\n",
      "Session [SESSION_ID_1]\n",
      "\n",
      "Account verification via £1 test card\n",
      "Card [CREDIT_CARD_NUMBER_1] exp [CARD_EXPIRY_1]\n",
      "\n",
      "Refs\n",
      "[CUSTOMER_REFERENCE_1]\n",
      "[ACCOUNT_ID_1]\n",
      "[SUPPORT_TICKET_NUMBER_1]\n",
      "\n",
      "Welcome email sent [DATE_1]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for test in _results[3:]:\n",
    "    print(test[2])\n",
    "    print(10*\"-----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proxyon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
